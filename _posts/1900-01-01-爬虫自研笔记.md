---
layout:     post
title:      爬虫自研笔记
subtitle:   潜龙，勿用
date:       1900-01-01
author:     Rainsblue.chan
header-img: ![3](../../../wallpaper/3.jpg)
catalog:   true
tags:
    - 经验
---
## 爬虫自研笔记
### 前言

​		用于学习爬虫的笔记，共勉。采用的课程为拉钩教育的爬虫课。

### 01.必知必会，掌握HTTP基本原理

#### URI、URL、URN

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621202914020.png" alt="image-20230621202914020" style="zoom:50%;" />

```URI和URL
例如：
https://github.com/favicon.ico既是一个URL，也是一个URI。
即有这样的一个图标资源，用URL/URI来唯一指定了它的访问方式，
这其中包括了访问协议HTTPS、访问路径（即github的根目录）和资源名称favicon.ico
```

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621203232056.png" alt="image-20230621203232056" style="zoom:50%;" />

URL（统一资源定位符）是URI（统一资源标识符）的一个子集，URI还有一个子类叫做URN（统一资源名称，**它只负责命名资源而不制定如何定位资源**）。所以这个URL的作用是资源的**定位**，这是标识的一个细化，可以说是**特别的标识**。**只要一个资源有定位符，它则一定是URI的一种**。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621203547812.png" alt="image-20230621203547812" style="zoom:50%;" />

我们看这幅图和这个例子，URN命名了一本书作为资源，它可以唯一标识这本书，**但是没有指定到哪里定位这本书**。

现在一般URN非常少，URL也可称作为URI（**网页链接**）。

![image-20230621204812916](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621204812916.png)

ctrl+u查看源代码，都是超文本。

#### HTTP和HTTPS概念

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621204937712.png" alt="image-20230621204937712" style="zoom:50%;" />

URL开头的这个http或者https就是访问资源所需要的协议类型。这两股协议是最常见的。我们来了解一下它们的含义。

![image-20230621205304617](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621205304617.png)

```HTTP概念
HTTP（Hyper Text Transfer Protocol）
中文名叫做超文本传输协议，用于从网络传输超文本数据到本地浏览器的传送协议，能保证高效而准确地传送超文本文档。
由来是万维网协会和IETF（互联网工作小组）共同指定的规范。
目前广泛使用的HTTP1.1版本。
```

![image-20230621205623679](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621205623679.png)

```HTTPS概念
多了一个套接层，SSL。大势所趋。
它的主要作用可以分为两种：
1.建立一个信息安全通道，来保证数据传输的安全
2.确认网站的真实性，凡是使用了HTTPS的网站，都可以通过点击浏览器地址的锁头标志来查看网站认证之后的真实信息，也可以通过CA机构颁发的安全签章来查询。
```

![image-20230621205952581](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621205952581.png)

#### HTTP请求过程

![image-20230621210134303](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621210134303.png)

输入URL，回车，实质是浏览器向网站服务器发送一个请求request，网站服务器接受到这个请求进行处理和解析，返回对应的response，传回给浏览器。响应里面会有网页源代码，浏览器会对这些超文本进行一个解析，就比如标签直接读掉，类似这种。

##### 开发者工具network选项卡使用

![image-20230621211021477](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621211021477.png)

![image-20230621211716430](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621211716430.png)

我们打开百度，进入开发者工具，查看网络选项卡。这里以我自己的截图举例子，我们看见网络下面有几个块，名称，状态，类型（type，指我们所请求的文件类型），启动器，大小，响应时间和可视化瀑布流。

我们这里以名称为“www.baidu.com"举例，它的状态为200，就是正常，类型为document，代表我们这里请求的是一个**“html文档”**，size如果是cache就是缓存的概念，说明曾经打开过这个网站？不是很理解，但是不太重要。

这里type这个标签还是很重要的吧。

![image-20230621212051878](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621212051878.png)

点开它，能够详细看到它的一些信息。

##### General部分

Request URL是指请求的网页，Request Method是指请求方法，Status Code为状态码，Remote Address，远程服务器地址端口，Referer Policy是判别策略。

响应头和请求头，请求头中带有许多请求信息，例如**浏览器标识**，**cookie**，**Host**等信息。这是请求的一部分。

![image-20230621225725985](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621225725985.png)

服务器会**根据请求头内的信息判断请求是否合法**，进而做出对应的响应。Response Headers就是响应的一部分。

![image-20230621225923041](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621225923041.png)

当中包含了服务器的类型，文档的类型，日期，这里GMT就是格林威治时间，我们在东八区，所以可知我现在是2023年6月21号晚上九点十六分在百度进行了一次请求。Server这里是百度自己的服务器，我搜了一下。

![image-20230621230258564](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621230258564.png)

还有一篇相关问答，[说是用来代替阿帕奇的](http://www.aiyiweb.com/linux/22997)。链接附在这段字下面了。

浏览器接收到响应会解析响应内容并显示在网页上。

#### 请求（GET和POST）

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621230613872.png" alt="image-20230621230613872" style="zoom:50%;" />

![image-20230621231325437](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621231325437.png)

做web题的时候也常用这种方式，就是一个？跟着所需参数=某个数值。经常就是?c=system('tac fla?.txt');这种形式，就是**GET传参**

![image-20230621231340881](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621231340881.png)

这点也有一点点体会，我记得post传参是以表单的形式，不是在url中修改，一般都是hackbar直接post。我们看一下区别。

![image-20230621232259056](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621232259056.png)

就两个区别，一个是get传参写在url里面，post是写在请求体里的，另外一个是字节限制，get最多1024bytes，post则没有限制。

一般来说，登陆时包含了登陆密码，其中涉及到了**敏感信息**，使用GET的方式，密码就会暴露在url里面，造成密码的泄露，所以最好以post的方式发送，较大也会用post。

还有一些其他的请求方式，总结为下表。

![image-20230621232805049](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621232805049.png)

请求的网址，即**统一资源定位符URL**，可以唯一确定我们想请求的资源。请求头说明了附加信息，比较重要的信息有**cookie、referer、user-agent**

#### （重要）请求头分析（cookie、referer、user-agent）

![image-20230621232916967](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621232916967.png)

![image-20230621233228239](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621233228239.png)

![image-20230621233542244](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621233542244.png)

![image-20230621233736681](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621233736681.png)

![image-20230621234028796](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621234028796.png)

```分析ing
Accept：请求报头域，用于指定客户端可接受哪些类型的信息
这里我们看，text/html代表html格式，也有图像类image/apng代表apng图片，application/xhtml+xml代表xhtml+xml类型。当中其实是Content-Type，对照表网址为http://tool.oschina.net/commons,
Accept-Language：指定客户端可接受的语言类型
这里支持中文英文。
Accept-Encoding：指定客户端可接受的内容编码
gzip，deflate，br
Host：用于指定请求资源的主机IP和端口号，其内容为请求URL的原始服务器或网关的位置，从HTTP1.1版本开始，请求必须包含此内容
这里看见Host就是baidu。
Cookie：很重要，这是网站为了辨别用户进行会话跟踪而存储在用户本地的数据，它的主要功能是维持当前访问会话。如果你讲一个登陆了的网站的cookie删除，那么自动你就从网页中掉出去。上面那张图解释的很清楚了。
```

![image-20230621234055032](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621234055032.png)

![image-20230621234128871](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621234128871.png)

![image-20230621234331459](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621234331459.png)

所以Referer是标识请求来源，UA则是标识客户使用的操作系统及版本，比如你可以使得一个普通浏览器换成微信浏览器的标识，这样你就可以伪装成微信浏览器。

在写爬虫时，大部分时间都需要请求头。

#### 请求体

![image-20230621234655724](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621234655724.png)

登录github输入完账号密码，这样回车之后就会以表单形式提交给服务器，此时需要注意，**request headers制定content-type为application/x-www-form-urlencoded**，才会以表单的数据形式提交。以url形式编码。

也可以将content-type设置为json，来提交json的内容。或者设置multipart/form-data来上传文件。

![image-20230621235325396](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621235325396.png)

在制作爬虫时，如果需要使用post，必须正确了解content-type。、

#### 响应体

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621235456734.png" alt="image-20230621235456734" style="zoom:50%;" />

有各种状态码，一般200就是正常返回数据。其他遇到问题再搜。

![image-20230621235602881](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621235602881.png)

![image-20230621225923041](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621225923041.png)

响应编码为gzip，文档类型返回为text/html，html文档，用的utf-8编码，Server为百度自研1.1，这里有三个set-cookies，我估计是有不同的地方会用到，比如搜索栏，比如登录。

![image-20230622000611300](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230622000611300.png)

响应体就是爬虫最后要解析的东西。

请求网页返回html源码，而图片则是它的二进制。

### 02.夯实根基，Web 网页基础

#### 网页的组成三大件：HTML、JavaScript、CSS

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230622213016300.png" alt="image-20230622213016300" style="zoom:67%;" />

HTML相当于骨架、CSS是渲染格式，所以是皮肤、JavaScript是脚本，执行操作，所以相当于人体运动的肌肉，三者完整结合在一起才能形成网页。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624134740705.png" alt="image-20230624134740705" style="zoom:50%;" />

HTML定义网页的内容和结构，CSS描述网页的布局，JavaScript定义网页的行为。

##### HTML（Hyper Text Markup Language，超文本标记语言）

HTML是用来**描述网页**的一种语言

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624113333616.png" alt="image-20230624113333616" style="zoom:67%;" />

不同类型的元素通过不同类型标签来表示，如上图所示。

在网页当中选择开发者模式，elements选项卡中展示的就是HTML源码。下图为示例。

这里就是用div嵌套做一个个模块。

![image-20230624113600325](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624113600325.png)

![image-20230624122903222](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624122903222.png)

相互嵌套组合，形成了网页架构。但只有html的元素的网页并不美观，为了让网页更加美观，所以出现了CSS。

##### CSS（Cascading Style Sheets，层叠样式表）

![image-20230624123518409](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624123518409.png)

层叠是**排版**，而样式更像是word文档中调整文字格式大小，颜色等等的一个操作。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624130033048.png" alt="image-20230624130033048" style="zoom:50%;" />

```css
#head_wrapper.s-ps-islite.s-p-top{		
#大括号前面是一个css选择器，这个选择器的作用首先是选中id为head_wrapper且class为s-ps-islite节点，然后再选中其中为s-p-top的节点
大括号其中的就是一条条样式规则
postion指定了这个元素的布局方式为绝对布局（absolute）
bottom指定了元素的下边距为40像素
width决定了宽度占百分之百
height决定元素的高度
```

等于就是我们把位置、宽度、高度统一写成这样的形式，然后用大括号括起来，接着在开头补充一个css选择器，这就代表**css选择器对于选中的元素生效了**。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624133009812.png" alt="image-20230624133009812" style="zoom: 50%;" />

我们看上面举过的实例。这里就是引用了testcss.css作为自己网页的一个层叠样式表。

![image-20230624133133012](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624133133012.png)

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624133358466.png" alt="image-20230624133358466" style="zoom:50%;" />

我们可以相对来修改一下它，比如图片之类的，就能够更好地来理解。

![image-20230624133553857](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624133553857.png)

这里我将第一块的图片给换了，就长这样。

现在HTML和CSS只是静态信息，为了使得网页具有交互效果，我们需要JS。

##### JavaScript（简称JS，一种脚本语言）

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624134027750.png" alt="image-20230624134027750" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624134101213.png" alt="image-20230624134101213" style="zoom:50%;" />

就如上图所示，在HTML中通过script，也就是JavaScript的script标签引入。script本身的意思就是脚本，所以这就是脚本标签。

#### 网页的结构

![image-20230624135541944](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624135541944.png)

```
这里比较重要的是要注意div标签。它定义了网页中的区块，id是container，这是一个非常常用的属性，且id在网页中的内容是唯一的。我们可以通过它来获取这个区块。
这个区块内又有一个div标签，这里定义一个class为wrapper，这也是非常常用的属性，经常与css配合使用来设定样式。
```

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624135250017.png" alt="image-20230624135250017" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624140659775.png" alt="image-20230624140659775" style="zoom:67%;" />

新建一个文本文件，然后应该在浏览器上的呈现就会是这样。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624135949771.png" alt="image-20230624135949771" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624140017080.png" alt="image-20230624140017080" style="zoom:50%;" />

这里我们就有这样一个例子，作者没用id的方式，而是直接用class，说明内容量不多吧，然后直接引用的css中的div.第一块来作为一个样式的修改。

#### 节点树及节点间的关系（DOM）

在HTML中，**所有标签定义的内容都是节点**，它们构成了一个**HTML DOM树**。

DOM是W3C（万维网联盟）的标准，其英文全称为Document Object Model，即文档对象模型。

![image-20230624140942015](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624140942015.png)

DOM是一个接口，用于程序、脚本动态访问，更新文档内容、结构和样式。

W3C也根据对象分为3个不同的部分，核心DOM（**针对任何结构化文档，泛用性广**），XML DOM（只针对XML文档），HTML DOM（只针对HTML）。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624141550927.png" alt="image-20230624141550927" style="zoom:67%;" />

根据W3C的HTML DOM标准，HTML文档中的所有内容都是节点：

- 整个文档是一个文档节点
- 每个HTML元素是元素节点
- HTML元素内的文本是文本节点
- 每个HTML属性是属性节点
- 注释是注释节点

##### HTML节点树

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624141905083.png" alt="image-20230624141905083" style="zoom:50%;" />

```HTML节点树
通过HTML DOM
树中的所有节点均可通过JavaScript访问
所有HTML节点元素均可被修改
也可以被创建或删除
```

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624142239775.png" alt="image-20230624142239775" style="zoom:50%;" />

##### 定位节点（css选择器）

> 一般我们会用css选择器来定位节点，比如<div id="container">

这个就表示为 **#container**，其中  #  开头代表选择id，其后紧跟id的名称。

如果要选择class为wrapper的节点，可以使用  **.wrapper**

这里  .  开头代表选择class，其后紧跟class的名称，也可使用根据标签名筛选，如想选择二级标题，直接用h2即可。

![image-20230624142658900](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624142658900.png)

支持**嵌套选择**，各个选择器加上空格分隔开代表嵌套。如#container .wrapper p（中间有两个空格）

- 代表先选择id为container的节点
- 然后再选中其**内部**为wrapper的节点
- 然后再进一步选中其内部的p节点

如果不加空格，则代表**并列关系**，如div#container .wrapper p.text（但这个例子应该是没有并列...）

- 代表先选择id为container的div节点
- 然后选中其内部的class为wrapper的节点
- 再进一步选中其内部的class为text的p节点

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624143801110.png" alt="image-20230624143801110" style="zoom:67%;" />

这里能看见并列关系用的是**逗号，** 

还有一种常用的选择器是**XPath**，之后会提到。

### 03.原理探究，了解爬虫的基本原理

#### 爬虫概述

爬虫就是获取网页并提取和保存信息的自动化程序。蜘蛛通过节点连线，获取下一个节点，这样所有的节点都可以被爬取到。

##### 获取网页

爬虫首先要做的就是**获取网页**，就是获取网页的源代码。

**源代码里包含网页的部分有用信息**，只要把源代码获取下来，就可以从中提取想要的信息。

前面讲了**请求**和**响应**的概念。向服务器发送一个请求，返回的**响应体**便是网页的源代码。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626091852403.png" alt="image-20230626091852403" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626091918093.png" alt="image-20230626091918093" style="zoom:50%;" />

我们可以利用这些库非常方便地完成**HTTP请求操作**。

请求和响应都可以用类库提供的数据结构来表示。得到响应之后，只需要解析数据结构中的body部分即可，即得到**网页源代码**。这样我们就可以用程序来实现获取网页内容的过程了。

##### 提取信息

获取网页源代码后，接下来就是分析网页源代码，从中提取想要的数据。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626092416653.png" alt="image-20230626092416653" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626092432288.png" alt="image-20230626092432288" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626092446589.png" alt="image-20230626092446589" style="zoom:50%;" />

```
两种方法：
最通用的方法是采用正则表达式提取，这是万能方案，但是构造容易出错。
第二种方法基于网页结构的规则，所以有一些根据网页节点属性、css选择器或XPath来提取网页信息的库，
比如Beautiful Soup、pyquery、lxml等等，它们可以高效提取节点属性、文本值等等。
```

##### 保存数据

提取信息后，一般会将提取到的数据保存到某处以便后续使用。

保存形式多种多样，如可以简单保存为**TXT文本或者JSON文本**。

也可以保存到数据库，如**MySQL和MongoDB**等。

还可以保存到远程服务器，如**借助SFTP进行操作**等。

##### 自动化程序

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626092923370.png" alt="image-20230626092923370" style="zoom:50%;" />

自动化程序的出现就是为了大量采集数据。

#### 能抓怎样的数据

```
在网页中能看到各种各样的信息，最常见的便是常规网页，它们对应着HTML代码，而最常抓取的便是HTML源代码。

有些网页返回的不是HTML代码，而是一个JSON字符串。而且这种数据提取会更加方便。

网页中还会有二进制文件，比如图片，视频和音频，利用爬虫可以将他们捕捉下来改成对应文件名。
```

#### JavaScript渲染页面

有时用urllib或requests抓取网页时，**得到的源代码实际和浏览器中看到的不一样**。

这是非常常见的情况，现在网页越来越多的采用**Ajax、前端模块化工具**来构建，

整个网页可能都是有JavaScript渲染出来的，即通过这个脚本重新写入HTML代码。

**原始的HTML代码可能就是一个空壳。**

例子如下图。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626094244345.png" alt="image-20230626094244345" style="zoom:50%;" />

这里我们看见在html代码中body里只有一个节点为container。后面呢引入了这个app.js的脚本。

如果这个时候我们用urllib或者requests来做一个html的请求，那么得到的只会是这一段HTML的代码。

因此使用基本HTTP请求库得到的源代码可能和浏览器中的页面源代码不太一样，可以分析其后台Ajax接口，也可使用Selenium、Splash这样的库来实现模拟JavaScript渲染。

### 04.基础探究，Session与Cookies

我们在网页浏览时经常会遇到登录的情况，有些网页只有登录之后才能够访问，而登录之后可以连续很多次的访问网站，但是有时候过一段时间就需要重新登录。还有一些网站，打开浏览器就自动登录了，而且很长时间都不会失效。

这种情况设计**Session和Cookies**的相关知识。

#### 静态网页和动态网页

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626095228058.png" alt="image-20230626095228058" style="zoom:50%;" />

静态网页一般会放在公网服务器上，一般配置有nginx或者apache。

但是存在很大缺陷，比如**可维护性差，不能根据URL灵活多变地显示内容**等。比如输入一个name参数，就没有办法找。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626095431401.png" alt="image-20230626095431401" style="zoom: 67%;" />

动态网页可以动态解析URL中参数的变化，**关联数据库**并动态呈现不同的页面内容，非常灵活多变。

现在遇到的大多数网站都是动态网站，不再是一个简单的HTML。

可能由JSP、PHP、Python等语言编写，其功能比静态网页强大和丰富太多，

动态网站还可以实现用户登录和注册的功能。

这种功能需要一个**特殊的凭证**，而这就是**Session和Cookies**的作用。

而在了解它们之前，我们必须了解HTTP的一个特点，叫做无状态。

#### 无状态HTTP



