---
layout:     post
title:      爬虫自研笔记
subtitle:   潜龙，勿用
date:       1900-01-01
author:     Rainsblue.chan
header-img: ![3](../../../wallpaper/3.jpg)
catalog:   true
tags:
    - 经验
---
## 爬虫自研笔记
### 前言

​		用于学习爬虫的笔记，共勉。采用的课程为拉钩教育的爬虫课。

### 01.必知必会，掌握HTTP基本原理

#### URI、URL、URN

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621202914020.png" alt="image-20230621202914020" style="zoom:50%;" />

```URI和URL
例如：
https://github.com/favicon.ico既是一个URL，也是一个URI。
即有这样的一个图标资源，用URL/URI来唯一指定了它的访问方式，
这其中包括了访问协议HTTPS、访问路径（即github的根目录）和资源名称favicon.ico
```

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621203232056.png" alt="image-20230621203232056" style="zoom:50%;" />

URL（统一资源定位符）是URI（统一资源标识符）的一个子集，URI还有一个子类叫做URN（统一资源名称，**它只负责命名资源而不制定如何定位资源**）。所以这个URL的作用是资源的**定位**，这是标识的一个细化，可以说是**特别的标识**。**只要一个资源有定位符，它则一定是URI的一种**。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621203547812.png" alt="image-20230621203547812" style="zoom:50%;" />

我们看这幅图和这个例子，URN命名了一本书作为资源，它可以唯一标识这本书，**但是没有指定到哪里定位这本书**。

现在一般URN非常少，URL也可称作为URI（**网页链接**）。

![image-20230621204812916](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621204812916.png)

ctrl+u查看源代码，都是超文本。

#### HTTP和HTTPS概念

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621204937712.png" alt="image-20230621204937712" style="zoom:50%;" />

URL开头的这个http或者https就是访问资源所需要的协议类型。这两股协议是最常见的。我们来了解一下它们的含义。

![image-20230621205304617](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621205304617.png)

```HTTP概念
HTTP（Hyper Text Transfer Protocol）
中文名叫做超文本传输协议，用于从网络传输超文本数据到本地浏览器的传送协议，能保证高效而准确地传送超文本文档。
由来是万维网协会和IETF（互联网工作小组）共同指定的规范。
目前广泛使用的HTTP1.1版本。
```

![image-20230621205623679](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621205623679.png)

```HTTPS概念
多了一个套接层，SSL。大势所趋。
它的主要作用可以分为两种：
1.建立一个信息安全通道，来保证数据传输的安全
2.确认网站的真实性，凡是使用了HTTPS的网站，都可以通过点击浏览器地址的锁头标志来查看网站认证之后的真实信息，也可以通过CA机构颁发的安全签章来查询。
```

![image-20230621205952581](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621205952581.png)

#### HTTP请求过程

![image-20230621210134303](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621210134303.png)

输入URL，回车，实质是浏览器向网站服务器发送一个请求request，网站服务器接受到这个请求进行处理和解析，返回对应的response，传回给浏览器。响应里面会有网页源代码，浏览器会对这些超文本进行一个解析，就比如标签直接读掉，类似这种。

##### 开发者工具network选项卡使用

![image-20230621211021477](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621211021477.png)

![image-20230621211716430](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621211716430.png)

我们打开百度，进入开发者工具，查看网络选项卡。这里以我自己的截图举例子，我们看见网络下面有几个块，名称，状态，类型（type，指我们所请求的文件类型），启动器，大小，响应时间和可视化瀑布流。

我们这里以名称为“www.baidu.com"举例，它的状态为200，就是正常，类型为document，代表我们这里请求的是一个**“html文档”**，size如果是cache就是缓存的概念，说明曾经打开过这个网站？不是很理解，但是不太重要。

这里type这个标签还是很重要的吧。

![image-20230621212051878](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621212051878.png)

点开它，能够详细看到它的一些信息。

##### General部分

Request URL是指请求的网页，Request Method是指请求方法，Status Code为状态码，Remote Address，远程服务器地址端口，Referer Policy是判别策略。

响应头和请求头，请求头中带有许多请求信息，例如**浏览器标识**，**cookie**，**Host**等信息。这是请求的一部分。

![image-20230621225725985](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621225725985.png)

服务器会**根据请求头内的信息判断请求是否合法**，进而做出对应的响应。Response Headers就是响应的一部分。

![image-20230621225923041](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621225923041.png)

当中包含了服务器的类型，文档的类型，日期，这里GMT就是格林威治时间，我们在东八区，所以可知我现在是2023年6月21号晚上九点十六分在百度进行了一次请求。Server这里是百度自己的服务器，我搜了一下。

![image-20230621230258564](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621230258564.png)

还有一篇相关问答，[说是用来代替阿帕奇的](http://www.aiyiweb.com/linux/22997)。链接附在这段字下面了。

浏览器接收到响应会解析响应内容并显示在网页上。

#### 请求（GET和POST）

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621230613872.png" alt="image-20230621230613872" style="zoom:50%;" />

![image-20230621231325437](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621231325437.png)

做web题的时候也常用这种方式，就是一个？跟着所需参数=某个数值。经常就是?c=system('tac fla?.txt');这种形式，就是**GET传参**

![image-20230621231340881](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621231340881.png)

这点也有一点点体会，我记得post传参是以表单的形式，不是在url中修改，一般都是hackbar直接post。我们看一下区别。

![image-20230621232259056](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621232259056.png)

就两个区别，一个是get传参写在url里面，post是写在请求体里的，另外一个是字节限制，get最多1024bytes，post则没有限制。

一般来说，登陆时包含了登陆密码，其中涉及到了**敏感信息**，使用GET的方式，密码就会暴露在url里面，造成密码的泄露，所以最好以post的方式发送，较大也会用post。

还有一些其他的请求方式，总结为下表。

![image-20230621232805049](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621232805049.png)

请求的网址，即**统一资源定位符URL**，可以唯一确定我们想请求的资源。请求头说明了附加信息，比较重要的信息有**cookie、referer、user-agent**

#### （重要）请求头分析（cookie、referer、user-agent）

![image-20230621232916967](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621232916967.png)

![image-20230621233228239](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621233228239.png)

![image-20230621233542244](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621233542244.png)

![image-20230621233736681](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621233736681.png)

![image-20230621234028796](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621234028796.png)

```分析ing
Accept：请求报头域，用于指定客户端可接受哪些类型的信息
这里我们看，text/html代表html格式，也有图像类image/apng代表apng图片，application/xhtml+xml代表xhtml+xml类型。当中其实是Content-Type，对照表网址为http://tool.oschina.net/commons,
Accept-Language：指定客户端可接受的语言类型
这里支持中文英文。
Accept-Encoding：指定客户端可接受的内容编码
gzip，deflate，br
Host：用于指定请求资源的主机IP和端口号，其内容为请求URL的原始服务器或网关的位置，从HTTP1.1版本开始，请求必须包含此内容
这里看见Host就是baidu。
Cookie：很重要，这是网站为了辨别用户进行会话跟踪而存储在用户本地的数据，它的主要功能是维持当前访问会话。如果你讲一个登陆了的网站的cookie删除，那么自动你就从网页中掉出去。上面那张图解释的很清楚了。
```

![image-20230621234055032](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621234055032.png)

![image-20230621234128871](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621234128871.png)

![image-20230621234331459](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621234331459.png)

所以Referer是标识请求来源，UA则是标识客户使用的操作系统及版本，比如你可以使得一个普通浏览器换成微信浏览器的标识，这样你就可以伪装成微信浏览器。

在写爬虫时，大部分时间都需要请求头。

#### 请求体

![image-20230621234655724](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621234655724.png)

登录github输入完账号密码，这样回车之后就会以表单形式提交给服务器，此时需要注意，**request headers制定content-type为application/x-www-form-urlencoded**，才会以表单的数据形式提交。以url形式编码。

也可以将content-type设置为json，来提交json的内容。或者设置multipart/form-data来上传文件。

![image-20230621235325396](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621235325396.png)

在制作爬虫时，如果需要使用post，必须正确了解content-type。、

#### 响应体

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621235456734.png" alt="image-20230621235456734" style="zoom:50%;" />

有各种状态码，一般200就是正常返回数据。其他遇到问题再搜。

![image-20230621235602881](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621235602881.png)

![image-20230621225923041](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230621225923041.png)

响应编码为gzip，文档类型返回为text/html，html文档，用的utf-8编码，Server为百度自研1.1，这里有三个set-cookies，我估计是有不同的地方会用到，比如搜索栏，比如登录。

![image-20230622000611300](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230622000611300.png)

响应体就是爬虫最后要解析的东西。

请求网页返回html源码，而图片则是它的二进制。

### 02.夯实根基，Web 网页基础

#### 网页的组成三大件：HTML、JavaScript、CSS

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230622213016300.png" alt="image-20230622213016300" style="zoom:67%;" />

HTML相当于骨架、CSS是渲染格式，所以是皮肤、JavaScript是脚本，执行操作，所以相当于人体运动的肌肉，三者完整结合在一起才能形成网页。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624134740705.png" alt="image-20230624134740705" style="zoom:50%;" />

HTML定义网页的内容和结构，CSS描述网页的布局，JavaScript定义网页的行为。

##### HTML（Hyper Text Markup Language，超文本标记语言）

HTML是用来**描述网页**的一种语言

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624113333616.png" alt="image-20230624113333616" style="zoom:67%;" />

不同类型的元素通过不同类型标签来表示，如上图所示。

在网页当中选择开发者模式，elements选项卡中展示的就是HTML源码。下图为示例。

这里就是用div嵌套做一个个模块。

![image-20230624113600325](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624113600325.png)

![image-20230624122903222](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624122903222.png)

相互嵌套组合，形成了网页架构。但只有html的元素的网页并不美观，为了让网页更加美观，所以出现了CSS。

##### CSS（Cascading Style Sheets，层叠样式表）

![image-20230624123518409](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624123518409.png)

层叠是**排版**，而样式更像是word文档中调整文字格式大小，颜色等等的一个操作。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624130033048.png" alt="image-20230624130033048" style="zoom:50%;" />

```css
#head_wrapper.s-ps-islite.s-p-top{		
#大括号前面是一个css选择器，这个选择器的作用首先是选中id为head_wrapper且class为s-ps-islite节点，然后再选中其中为s-p-top的节点
大括号其中的就是一条条样式规则
postion指定了这个元素的布局方式为绝对布局（absolute）
bottom指定了元素的下边距为40像素
width决定了宽度占百分之百
height决定元素的高度
```

等于就是我们把位置、宽度、高度统一写成这样的形式，然后用大括号括起来，接着在开头补充一个css选择器，这就代表**css选择器对于选中的元素生效了**。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624133009812.png" alt="image-20230624133009812" style="zoom: 50%;" />

我们看上面举过的实例。这里就是引用了testcss.css作为自己网页的一个层叠样式表。

![image-20230624133133012](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624133133012.png)

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624133358466.png" alt="image-20230624133358466" style="zoom:50%;" />

我们可以相对来修改一下它，比如图片之类的，就能够更好地来理解。

![image-20230624133553857](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624133553857.png)

这里我将第一块的图片给换了，就长这样。

现在HTML和CSS只是静态信息，为了使得网页具有交互效果，我们需要JS。

##### JavaScript（简称JS，一种脚本语言）

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624134027750.png" alt="image-20230624134027750" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624134101213.png" alt="image-20230624134101213" style="zoom:50%;" />

就如上图所示，在HTML中通过script，也就是JavaScript的script标签引入。script本身的意思就是脚本，所以这就是脚本标签。

#### 网页的结构

![image-20230624135541944](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624135541944.png)

```
这里比较重要的是要注意div标签。它定义了网页中的区块，id是container，这是一个非常常用的属性，且id在网页中的内容是唯一的。我们可以通过它来获取这个区块。
这个区块内又有一个div标签，这里定义一个class为wrapper，这也是非常常用的属性，经常与css配合使用来设定样式。
```

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624135250017.png" alt="image-20230624135250017" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624140659775.png" alt="image-20230624140659775" style="zoom:67%;" />

新建一个文本文件，然后应该在浏览器上的呈现就会是这样。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624135949771.png" alt="image-20230624135949771" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624140017080.png" alt="image-20230624140017080" style="zoom:50%;" />

这里我们就有这样一个例子，作者没用id的方式，而是直接用class，说明内容量不多吧，然后直接引用的css中的div.第一块来作为一个样式的修改。

#### 节点树及节点间的关系（DOM）

在HTML中，**所有标签定义的内容都是节点**，它们构成了一个**HTML DOM树**。

DOM是W3C（万维网联盟）的标准，其英文全称为Document Object Model，即文档对象模型。

![image-20230624140942015](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624140942015.png)

DOM是一个接口，用于程序、脚本动态访问，更新文档内容、结构和样式。

W3C也根据对象分为3个不同的部分，核心DOM（**针对任何结构化文档，泛用性广**），XML DOM（只针对XML文档），HTML DOM（只针对HTML）。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624141550927.png" alt="image-20230624141550927" style="zoom:67%;" />

根据W3C的HTML DOM标准，HTML文档中的所有内容都是节点：

- 整个文档是一个文档节点
- 每个HTML元素是元素节点
- HTML元素内的文本是文本节点
- 每个HTML属性是属性节点
- 注释是注释节点

##### HTML节点树

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624141905083.png" alt="image-20230624141905083" style="zoom:50%;" />

```HTML节点树
通过HTML DOM
树中的所有节点均可通过JavaScript访问
所有HTML节点元素均可被修改
也可以被创建或删除
```

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624142239775.png" alt="image-20230624142239775" style="zoom:50%;" />

##### 定位节点（css选择器）

> 一般我们会用css选择器来定位节点，比如<div id="container">

这个就表示为 **#container**，其中  #  开头代表选择id，其后紧跟id的名称。

如果要选择class为wrapper的节点，可以使用  **.wrapper**

这里  .  开头代表选择class，其后紧跟class的名称，也可使用根据标签名筛选，如想选择二级标题，直接用h2即可。

![image-20230624142658900](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624142658900.png)

支持**嵌套选择**，各个选择器加上空格分隔开代表嵌套。如#container .wrapper p（中间有两个空格）

- 代表先选择id为container的节点
- 然后再选中其**内部**为wrapper的节点
- 然后再进一步选中其内部的p节点

如果不加空格，则代表**并列关系**，如div#container .wrapper p.text（但这个例子应该是没有并列...）

- 代表先选择id为container的div节点
- 然后选中其内部的class为wrapper的节点
- 再进一步选中其内部的class为text的p节点

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230624143801110.png" alt="image-20230624143801110" style="zoom:67%;" />

这里能看见并列关系用的是**逗号，** 

还有一种常用的选择器是**XPath**，之后会提到。

### 03.原理探究，了解爬虫的基本原理

#### 爬虫概述

爬虫就是获取网页并提取和保存信息的自动化程序。蜘蛛通过节点连线，获取下一个节点，这样所有的节点都可以被爬取到。

##### 获取网页

爬虫首先要做的就是**获取网页**，就是获取网页的源代码。

**源代码里包含网页的部分有用信息**，只要把源代码获取下来，就可以从中提取想要的信息。

前面讲了**请求**和**响应**的概念。向服务器发送一个请求，返回的**响应体**便是网页的源代码。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626091852403.png" alt="image-20230626091852403" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626091918093.png" alt="image-20230626091918093" style="zoom:50%;" />

我们可以利用这些库非常方便地完成**HTTP请求操作**。

请求和响应都可以用类库提供的数据结构来表示。得到响应之后，只需要解析数据结构中的body部分即可，即得到**网页源代码**。这样我们就可以用程序来实现获取网页内容的过程了。

##### 提取信息

获取网页源代码后，接下来就是分析网页源代码，从中提取想要的数据。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626092416653.png" alt="image-20230626092416653" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626092432288.png" alt="image-20230626092432288" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626092446589.png" alt="image-20230626092446589" style="zoom:50%;" />

```
两种方法：
最通用的方法是采用正则表达式提取，这是万能方案，但是构造容易出错。
第二种方法基于网页结构的规则，所以有一些根据网页节点属性、css选择器或XPath来提取网页信息的库，
比如Beautiful Soup、pyquery、lxml等等，它们可以高效提取节点属性、文本值等等。
```

##### 保存数据

提取信息后，一般会将提取到的数据保存到某处以便后续使用。

保存形式多种多样，如可以简单保存为**TXT文本或者JSON文本**。

也可以保存到数据库，如**MySQL和MongoDB**等。

还可以保存到远程服务器，如**借助SFTP进行操作**等。

##### 自动化程序

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626092923370.png" alt="image-20230626092923370" style="zoom:50%;" />

自动化程序的出现就是为了大量采集数据。

#### 能抓怎样的数据

```
在网页中能看到各种各样的信息，最常见的便是常规网页，它们对应着HTML代码，而最常抓取的便是HTML源代码。

有些网页返回的不是HTML代码，而是一个JSON字符串。而且这种数据提取会更加方便。

网页中还会有二进制文件，比如图片，视频和音频，利用爬虫可以将他们捕捉下来改成对应文件名。
```

#### JavaScript渲染页面

有时用urllib或requests抓取网页时，**得到的源代码实际和浏览器中看到的不一样**。

这是非常常见的情况，现在网页越来越多的采用**Ajax、前端模块化工具**来构建，

整个网页可能都是有JavaScript渲染出来的，即通过这个脚本重新写入HTML代码。

**原始的HTML代码可能就是一个空壳。**

例子如下图。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626094244345.png" alt="image-20230626094244345" style="zoom:50%;" />

这里我们看见在html代码中body里只有一个节点为container。后面呢引入了这个app.js的脚本。

如果这个时候我们用urllib或者requests来做一个html的请求，那么得到的只会是这一段HTML的代码。

因此使用基本HTTP请求库得到的源代码可能和浏览器中的页面源代码不太一样，可以分析其后台Ajax接口，也可使用Selenium、Splash这样的库来实现模拟JavaScript渲染。

### 04.基础探究，Session与Cookies

我们在网页浏览时经常会遇到登录的情况，有些网页只有登录之后才能够访问，而登录之后可以连续很多次的访问网站，但是有时候过一段时间就需要重新登录。还有一些网站，打开浏览器就自动登录了，而且很长时间都不会失效。

这种情况设计**Session和Cookies**的相关知识。

#### 静态网页和动态网页

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626095228058.png" alt="image-20230626095228058" style="zoom:50%;" />

静态网页一般会放在公网服务器上，一般配置有nginx或者apache。

但是存在很大缺陷，比如**可维护性差，不能根据URL灵活多变地显示内容**等。比如输入一个name参数，就没有办法找。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626095431401.png" alt="image-20230626095431401" style="zoom: 67%;" />

动态网页可以动态解析URL中参数的变化，**关联数据库**并动态呈现不同的页面内容，非常灵活多变。

现在遇到的大多数网站都是动态网站，不再是一个简单的HTML。

可能由JSP、PHP、Python等语言编写，其功能比静态网页强大和丰富太多，

动态网站还可以实现用户登录和注册的功能。

这种功能需要一个**特殊的凭证**，而这就是**Session和Cookies**的作用。

而在了解它们之前，我们必须了解HTTP的一个特点，叫做无状态。

#### 无状态HTTP

HTTP特点之一——**无状态**

是指**HTTP协议对事务处理是没有记忆能力的，也就是说服务器不知道客户端是什么状态**。

HTTP有点像我，记性很差。

当我们向服务器发送请求后，服务器解析这个请求，然后返回对你的响应，服务器负责完成这个过程，而且这个过程是完全独立的，**服务器不会记录前后状态的变化，也就是缺少记录。**

这就意味着，**如果后续需要处理前面的信息，则必须重传**，这也导致需要额外传递一些前面的重复请求，才能获取后续响应。然而这种效果肯定不是我们想要的，为了保持前面的状态，我们还得全部重传一次，这太浪费资源了，对于这种需要用户登录的页面来说，更是棘手。

```
例如，一个人需要登录网站，他做了一次这个操作，当他再需要进入网站，那么他还要做一次这个操作。（如果没有session和cookies）
```

于是两个保持HTTP连接状态的技术就出现力！就是我们的Session和Cookies。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626101348601.png" alt="image-20230626101348601" style="zoom:80%;" />

![image-20230626102557122](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626102557122.png)

在服务端：网站的服务器用来保存用户的Session信息，我们可以简单称之为**会话信息**。

在客户端：可以理解为浏览器端，浏览器在下次访问网页时会自动附带上它发送给服务器，**服务器通过识别Cookies并鉴定出是哪个用户，然后再判断用户是否是登录状态，进而返回对应的响应**。这种响应的表现形式就是你的网页，比如你在网页端登录了bilibili，那么这个时候的响应就是你的右上角有个头像。

有了cookies，浏览器在下次访问网页时，会自动附带上它，把他发送给服务器，我们可以理解为cookies里面保存了用户的凭证，因此下次登录就不需要再次输入用户名密码等信息，重新登陆。

因此在爬虫中，有时候处理一些需要登录才能访问的页面，我们一般**会将登录成功之后获取的这个cookies放在请求头中直接请求**，而不必重新模拟登录。

好了，详细地了解了它们的概念之后，我们剖析它们的原理。

#### Session（会话）

其本身的含义是指**有始有终的一系列动作/消息**。

比如打电话时，从拿起电话拨号到挂断电话这中间的一系列过程可以称为一个session，有点像反序列化中，我们的魔术手套，**不改变数据结构，但是只改变属性**，动作相同的证明，正式那个反序列化值。这里的session值，**就是这些动作的证明**。

在Web中，Session对象用来存储特定用户Session所需的属性及配置信息。这样当用户跳转页面，session变量中所存储的信息不会丢失。下面是百度的，讲的也差不离。

[session的概念](https://baike.baidu.com/item/session/479100?fr=aladdin)，在计算机中，尤其是在网络应用中，称为**“会话控制”**。**Session对象存储特定用户会话所需的属性及配置信息。**这样，当用户在应用程序的Web页之间跳转时，存储在Session对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。**（这样就不会被无状态，或说是无记忆的HTML影响）**当用户请求来自应用程序的 Web页时，如果该用户还没有会话，**则Web服务器将自动创建一个 Session对象。**当会话过期或被放弃后，服务器将终止该会话。Session 对象最常见的一个用法就是**存储用户的首选项**。例如，如果用户指明不喜欢查看图形，就可以将该信息存储在Session对象中。有关使用Session 对象的详细信息，请参阅“ASP应用程序”部分的“管理会话”。注意会话状态仅在支持cookie的浏览器中保留。

#### Cookies

指某些网站**为了辨别用户身份、进行Session跟踪而存储在用户本地终端上的数据**。

我们接下来讲一下这个过程：

##### **当客户端第一次请求服务器时**

服务器会返回一个响应头中带有**Set-Cookie字段**的响应给客户端

用来标记是哪一个用户，客户端浏览器会把Cookies保存起来

比如我这里搜索赛尔号，就是向百度的BWS服务器发送一个请求，这个post被解析之后会返回一个带有set-cookie字段的response，见下图，这用于标记我。

![image-20230626112827958](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626112827958.png)

##### **当浏览器下一次再请求该网站时**

浏览器会把此Cookies放到请求头一起提交给服务器

Cookies携带了Session ID信息，服务器检查该Cookies即可找到对应的Session是什么

然后判断Session来以此辨认用户状态

或者我们就说bilibili得了

![image-20230626113416909](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626113416909.png)

这是一样的，Set-Cookie会在这里做一个标记。这里有我的Session ID信息，然后就能交给服务器判断。

##### **在成功登录某个网站时**

服务器会告诉客户端设置哪些Cookies信息

在后续访问页面时客户端会把Cookies发送给服务器，服务器再找到对应的Session加以判断

如果Session中的某些设置登录状态的变量是有效的

就证明用户处于登录状态

**此时返回登录之后才可以查看的网页内容，浏览器再进行解析便可以看到了。**

反之，Cookies无效则返回上一页面。

##### Cookies位置

位于**开发者选项卡中application里的Storage**。

![image-20230626143637884](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626143637884.png)

这其中有很多条目，每一个条目都可以称作是一个**Cookie**。

它有以下几个属性：

- **Name**，即该Cookie的名称，这里要注意，**Cookie一旦创建，Name就不可能更改。**
- **Value**，即该Cookie的值，**如果值为Unicode字符，需要为字符编码**，**如果值为二进制属性，则需要使用base64编码**。

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626144155771.png" alt="image-20230626144155771" style="zoom:80%;" />

- **Expires/Max-Age**，第一个i-cookie（有点没听清）生成的时间，单位为秒。常和Expires一起使用，计算cookie有效时间。**Max-Age如果为正数，则value，cookie在（max-age秒）之后失效。如果Max-Age为负数，则关闭浏览器时cookie即失效。**（浏览器也不会以任何形式保存该cookie）

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626145029762.png" alt="image-20230626145029762" style="zoom:50%;" />

- **Path**，即该cookie的使用路径，如果设置为Path路径，将只有路径设置为path的路径能够访问该cookie。如果设置为根路径，则本域名下所有的页面都可以访问该cookie。
- **Domain**，即可以访问该cookie的域名。例如设置为.zhihu.com，则所有以zhihu.com为结尾的都可以访问该cookie。
- **Size**,cookie大小。
- **HTTP**，即**此cookie的HTTP-only属性**。若此属性为True，则只有在HTTP-header中会带有此cookie的信息。**而不能通过document.cookie来访问此cookie。

##### 会话Cookie和持久Cookie

会话Cookie（Session-Cookie）就是把Cookie放在浏览器内存里，浏览器在关闭之后该Cookie即失效（**短时使用**）

持久Cookie则会保存到客户端的硬盘中，下次还可以继续使用，用于长久保持用户登录状态

**严格来说**，没有会话Cookie和持久Cookie之分，只是由Cookie的Max Age或Expires字段决定了过期的时间。Max Age为正就是cookie在Max Age秒之后失效，为负就是关闭浏览器后失效。**持久Cookie就是相应把Session有效时间调长一些**。

#### 登录Session控制的实现图

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626143113839.png" alt="image-20230626143113839" style="zoom:50%;" />

登录会话控制由两者共同协作，服务器端是Session来记录会话信息和属性，客户端是Cookies来记录用户信息。以此来填补HTML的无状态（无记忆）。

#### 常见误区

##### **在谈论Session机制时**

并不是将浏览器关闭，Session就消失，**而是会保留在服务器上，除非程序通知服务器删除一个session**。

**比如程序一般都是在我们做注销操作时才去删除Session**。我们做个实例。

- **注销前**

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626151156571.png" alt="image-20230626151156571" style="zoom:67%;" />

- **注销后**

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230626151245663.png" alt="image-20230626151245663" style="zoom: 67%;" />

我们看见这个Session因为注销被删除了，关闭浏览器后Session也没有删除。

##### **当关闭浏览器时**

但是浏览器不会在关闭之前主动通知服务器它将要关闭，所以**服务器根本不会有机会知道浏览器已经关闭**。

之所以有这种错觉，是因为大部分网站都用的是会话Cookie。（**Cookie随关随注销**）当再次连接到服务器，没了cookie自然找不到session，不过，如果硬盘存储了cookie或是改写了请求头，那么仍然能恢复连接状态，找到session-id。

##### **由于关闭浏览器不会导致Session被删除**

这就需要服务器为Session设置一个失效时间，当距离客户端上一次使用Session的时间超过这个失效时间时，服务器就可以认为客户端已经停止了活动，才会把Session删除以节省存储空间。

### 05.多路加速，了解多线程基本原理

我们知道，在一台计算机中可以同时打开许多软件，比如同时打字听音乐。

这涉及到**多线程和多进程**。

为了提高爬虫效率，同样也需要这方面知识。我们这里主要是看如何在python中实现这种过程。

#### 多线程的含义

进程可以理解为一个**可以独立运行的程序单位**。比如开一个notepad，就是开启一个notepad进程。

一个进程中**可以同时处理很多事情**，比如浏览器可以在多个选项卡中打开多个页面，可以同时运行，互不干扰。

为什么能同时运行这么多任务？**任务对应着线程的执行。**

进程是线程的集合，是由一个或多个线程构成的，线程则是**操作系统进行运算调度的最小单位，是进程中的一个最小运行单元**。

比如上面的浏览器进程，播放音乐就是一个线程。

多线程就是**一个进程中同时执行多个线程**。

#### 并发和并行

![image-20230627073319815](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230627073319815.png)

并发只有一个核，同一时刻只能有一条指令，看上去多个线程同时执行，实际上是快速切换；

并行需要多处理器，多线程同一时刻执行。

#### 多线程适用场景

在一个程序进程中，有些操作是比较**耗时**或者**需要等待**的，如：

- 等待数据库的查询结果的返回
- 等待网页结果的响应

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230627073649527.png" alt="image-20230627073649527" style="zoom:80%;" />

使用单线程，处理器必须要等待这些操作完成才能继续执行，这个时候处理器被闲置；

使用多线程，处理器就可以在某个线程等待时执行其他线程，从而从整体上提高执行效率。

**网络爬虫**就是一个典型的例子，爬虫在向服务器发送请求之后，有一段时间必须要等待服务器的响应返回，这种任务就属于**IO密集型任务（IO-bound）（CPU相较为闲置）**。但也不是所有的任务都是IO-bound，还有**CPU密集型（CPU-bound）**，就是任务的运行一直需要处理器参与，这个时候IO就被闲置。**如果这个时候开启多线程，那么从一个cpu-bound切换到另一个cpu-bound，处理器依旧不会停下来，始终会忙于计算。（这样并不会节省总体的时间，因为所需要处理的任务量的总量是不变的）**

##### 总结

如果任务不全是CPU-bound，那么可以使用多线程来提高程序整体执行效率**（就是把CPU等待时间全给它变成执行）**，尤其对于**网络爬虫这种IO-bound任务**来说，使用多线程会**大大提高程序整体的爬取效率**。

#### Python实现多线程

##### threading、join、守护线程

在Python中，实现多线程的模块叫做**threading**，是Python自带的模块。下面开始演示。

```Python
# Author: Rainsblue.chan
# Create: 2023/6/27
# FileName: threadtest
import threading
import time

def target(second):
    print(f'Threading {threading.current_thread().name} is running')
    print(f'Threading {threading.current_thread().name} sleep {second}s')
    time.sleep(second)
    print(f'Threading {threading.current_thread().name} is ended')

print(f'Threading {threading.current_thread().name} is running')
for i in [1,5]:
    t = threading.Thread(target=target, args=[i])
    t.start()
    t.join()
print(f'Threading {threading.current_thread().name} is ended')
```

首先，我们可以使用thread类来创建一个线程。创建时需要**指定target参数为运行的方法名称**，如果被调用的方法需要插入额外的参数，则可以通过**thread-args**来指定。

在这里，我们首先声明了一个方法，叫做**target**。它接收一个参数叫做**second**，通过方法的实现可以发现，这个方法就是实现了一个**time.sleep**休眠操作，second参数就是**休眠秒数**。提前后print一些内容。其中线程的名字，我们可以通过**threading.current_thread().name**获取。如果是主线程，起值就是main thread，如果是子线程，起值就是thread-*，这个就是代表线程自己的名称。

然后我们通过thread类新建了两个线程，target参数就是我们定义的方法名，args，以列表的方式来呈递，两次循环中，这里i分别是1和5，这样两个线程休眠时间分别为1秒和5秒。声明完成之后，就可以通过start开始运行。

![image-20230627083218902](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230627083218902.png)

主线程首先运行结束，然后是两个子线程接连运行结束，分别间隔1秒和4秒。这说明主线程并没有等待子线程并结束运行，而是直接退出了，有些不符合常理。

如果我们想要主线程等待子线程运行完毕再退出，可以让每个子线程都调用下面的**join方法**。 

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230627084345524.png" alt="image-20230627084345524" style="zoom: 50%;" />

另外，也可以通过继承thread类的方式，需要在方法中写入run。

如果一个线程被设置为守护线程，那么就说明这个线程是不重要的。这就意味着如果主线程结束了，守护线程还没有运行完，那么它将被**强制结束**。在Python中，我们可以通过**setDaemon**方法来设置守护线程。

```Python
# Author: Rainsblue.chan
# Create: 2023/6/27
# FileName: threadtest
import threading
import time

def target(second):
    print(f'Threading {threading.current_thread().name} is running')
    print(f'Threading {threading.current_thread().name} sleep {second}s')
    time.sleep(second)
    print(f'Threading {threading.current_thread().name} is ended')

print(f'Threading {threading.current_thread().name} is running')
t1 = threading.Thread(target=target, args=[2])
t1.start()
t2 = threading.Thread(target=target, args=[5])
t2.setDaemon(True)	#3.7可以这么写，如果是3.10，用t.daemon=true
t2.start()
print(f'Threading {threading.current_thread().name} is ended')
```

![image-20230627085341040](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230627085341040.png)

这里我们没有看见Thread2退出的信息，说明随着MainThread的退出而退出了。这里并没有调用join方法，如果调用，仍然会等待，无论是否为守护线程。

图为加了join后

![image-20230627085713584](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230627085713584.png)

##### 互斥锁

在一个进程中的多个线程是共享资源的，比如在一个进程中有一个全局变量count用于计数，现在我们声明多个线程，每个线程运行值都给count加1，让我们看看效果如何。

```python
# Author: Rainsblue.chan
# Create: 2023/6/27
# FileName: threadtest
import threading
import time

count = 0

class MyThread(threading.Thread): # 定义一个创建线程
    def __init__(self):
        threading.Thread.__init__(self)

    def run(self):
        global count
        temp = count + 1
        time.sleep(0.001)
        count = temp

threads =[] # 创建一个空列表用于记录？大概
for _ in range(1000): # 不使用迭代变量，也就是同样内容执行1000次
    thread = MyThread()
    thread.start()
    threads.append(thread)

for thread in threads:
    thread.join() # 等待thread进程结束
print(f'Final count: {count}') # f-string，统计count次数
```

结果如下

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/image-20230627091624864.png" alt="image-20230627091624864" style="zoom:50%;" />

在这里我们声明了1000个线程，各休眠一小段时间，然后对count赋予新的值。那这样**按照常理，count值应该是1000**。但是count居然是8。原因是因为**count是共享的，每个线程都可以在执行count = temp这段代码时拿到count的值。但是这些线程可以是并发或者并行执行的。这就导致了不同的线程可能拿到的是同一个count值，加1操作也就没有生效，最后导致结果偏小。**不同的电脑可能在这里结果不一样，但是结果大致都是偏小的。

所以，**如果多个线程同时对某个数据进行读取或者修改，就会出现不可预料的结果**。为了避免这种情况，我们需要对多个线程进行**同步**，要实现同步，我们可以对需要操作的数据进行**加锁保护**。这里就需要threading.Lock（）了。

##### 加锁保护

某个线程在对数据进行操作前，需要先**加锁**，这样其他的线程发现被加锁了之后，就无法继续向下执行，会一直等待锁被释放，只有加锁的线程把锁释放了，其他的线程才能继续加锁并对数据做修改，修改完了再释放锁，**这样可以确保同一时间只有一个线程操作数据，多个线程不会再同时读取和修改同一个数据**，最后的运行结果就是对的了。我觉得这有点类似于并发。

```python
# Author: Rainsblue.chan
# Create: 2023/6/27
# FileName: threadtest
import threading
import time

count = 0

class MyThread(threading.Thread):
    def __init__(self):
        threading.Thread.__init__(self)

    def run(self):
        global count
        lock.acquire() # 获取count前先加锁
        temp = count + 1
        time.sleep(0.001)
        count = temp
        lock.release() # run完之后再释放锁

lock = threading.Lock()
threads =[] # 创建一个空列表用于记录？大概
for _ in range(1000): # 不使用迭代变量，也就是同样内容执行1000次
    thread = MyThread()
    thread.start()
    threads.append(thread)

for thread in threads:
    thread.join() # 等待thread进程结束
print(f'Final count: {count}') # f-string，统计count次数
```

在run方法中，在获取count前先加锁，等线程run完之后再释放锁。这样多个线程就不会同时修改操作同一个count值了。

![image-20230627094927086](C:/Users/14682/AppData/Roaming/Typora/typora-user-images/image-20230627094927086.png)

#### Python多线程的问题

**GIL**，全称为Global Interpreter Lock，译为**全局解释器锁**。其最初设计是为了数据安全而考虑的。

由于python中GIL的限制，**无论是多核和单核，同一时刻只能运行一个线程**，这直接**导致python多线程无法发挥多核并行的优势**。

在Python多线程下，每个线程的执行方式如下：

- 获取GIL
- 执行对应线程的代码
- 释放GIL

##### Python多线程下同一时刻只能运行一个线程的核心原因

我们可以把GIL想象成一张通信证，并且一个Python进程中只有一个GIL。拿不到通信证的线程就不允许执行，所以多线程下只能一个个来的原因，就在于此。

不过对于爬虫这种IO-bound来说，这个影响并不大（**原因是因为爬虫发送一个HTML请求后大多数时间都是在等待，cpu在这段时间内闲置**），而对于Cpu-bound，由于GIL的存在，多线程的效率可能会比单线程还低。

### 06.多路加速，了解多进程基本原理

